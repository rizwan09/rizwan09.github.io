---
title: "Fast and Robust Text Classification Model"
collection: talks
type: "Talk"
permalink: /talks/2019-nsyss
venue: "6th International Conference on Networking, Systems and Security (NSysS)"
date: 2019-12-02
location: "Dhaka, Bangladesh"
---

[[Presentation-slides]](https://drive.google.com/file/d/1c8QiTuKihpX6iheBiGuh3AHj_P-YSeKC/view?usp=sharing)
[[Presentation-pdf]](https://docs.google.com/presentation/d/1t0RnR9CDVZdphlaDvgduosflvLKvB8Ji/edit?usp=sharing&ouid=109501306155809246755&rtpof=true&sd=true)

======

<p align="justify">
Despite much success, the effectiveness of deep learning models largely rely on the availability of large amounts of labeled data. Labeled data, however, is costly to acquire in many applications of interest, which hinders the applicability of these models. Making use of unlabeled data to improve deep learning has been an important research direction to address this, yet, while doing so, the majority of them do not consider the structured linguistic information or leveraging other existing tools/methods prevailed in the literature and achieve limited gain. In this research, we explore the paradigm of applying data augmentation to unlabeled data by investigating how to incorporate additional information utilizing auxiliary sources while training a deep learning model efficiently and efficiently. Unlike previous approaches which are in general either rule-based or augment data by feature perturbation in supervised or semi-supervised manner, we study what auxiliary linguistic information can be integrated to enhance the current state-of-art deep learning models, and how to augment these features by the intelligent generation or extraction of task-specific linguistic information from the unlabeled data with mere supervision. Our approach encourages the deep learning model not only to realize high accuracy or faster inference but also to achieve consistency in its performance for any test-time scenarios. In our research, so far, the structured data augmentation has been attributed to text classification, and language modeling and planned to be leveraged soon in semantic role labeling, and unsupervised question answering. In this talk, we will discuss one of our previous work "Robust Text Classifier on Test-Time Budgets".

</p>
